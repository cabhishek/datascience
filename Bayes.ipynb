{
 "metadata": {
  "name": "",
  "signature": "sha256:470e9c38447211210f6f22460a26d112139029bceddfc28a92b5597e53df0454"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn import datasets, linear_model\n",
      "from sklearn.feature_extraction.text import CountVectorizer \n",
      "from sklearn.cross_validation import train_test_split\n",
      "from sklearn.naive_bayes import MultinomialNB\n",
      "from sklearn.cross_validation import cross_val_score\n",
      "\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "import nltk\n",
      "import glob\n",
      "import re\n",
      "\n",
      "stop_words = [\"br\",\"a\",\"able\",\"about\",\"across\",\"after\",\"all\",\"almost\",\"also\",\"am\",\"among\",\"an\",\"and\",\"any\",\"are\",\"as\",\"at\",\"be\",\"because\",\"been\",\"but\",\"by\",\"can\",\"cannot\",\"could\",\"dear\",\"did\",\"do\",\"does\",\"either\",\"else\",\"ever\",\"every\",\"for\",\"from\",\"get\",\"got\",\"had\",\"has\",\"have\",\"he\",\"her\",\"hers\",\"him\",\"his\",\"how\",\"however\",\"i\",\"if\",\"in\",\"into\",\"is\",\"it\",\"its\",\"just\",\"least\",\"let\",\"like\",\"likely\",\"may\",\"me\",\"might\",\"most\",\"must\",\"my\",\"neither\",\"no\",\"nor\",\"not\",\"of\",\"off\",\"often\",\"on\",\"only\",\"or\",\"other\",\"our\",\"own\",\"rather\",\"said\",\"say\",\"says\",\"she\",\"should\",\"since\",\"so\",\"some\",\"than\",\"that\",\"the\",\"their\",\"them\",\"then\",\"there\",\"these\",\"they\",\"this\",\"tis\",\"to\",\"too\",\"twas\",\"us\",\"wants\",\"was\",\"we\",\"were\",\"what\",\"when\",\"where\",\"which\",\"while\",\"who\",\"whom\",\"why\",\"will\",\"with\",\"would\",\"yet\",\"you\",\"your\",\"ain't\",\"aren't\",\"can't\",\"could've\",\"couldn't\",\"didn't\",\"doesn't\",\"don't\",\"hasn't\",\"he'd\",\"he'll\",\"he's\",\"how'd\",\"how'll\",\"how's\",\"i'd\",\"i'll\",\"i'm\",\"i've\",\"isn't\",\"it's\",\"might've\",\"mightn't\",\"must've\",\"mustn't\",\"shan't\",\"she'd\",\"she'll\",\"she's\",\"should've\",\"shouldn't\",\"that'll\",\"that's\",\"there's\",\"they'd\",\"they'll\",\"they're\",\"they've\",\"wasn't\",\"we'd\",\"we'll\",\"we're\",\"weren't\",\"what'd\",\"what's\",\"when'd\",\"when'll\",\"when's\",\"where'd\",\"where'll\",\"where's\",\"who'd\",\"who'll\",\"who's\",\"why'd\",\"why'll\",\"why's\",\"won't\",\"would've\",\"wouldn't\",\"you'd\",\"you'll\",\"you're\",\"you've\"]\n",
      "\n",
      "spam_path = \"/Users/akapatkar/Downloads/spam_2/*\"\n",
      "ham_path = \"/Users/akapatkar/Downloads/easy_ham/*\"\n",
      "\n",
      "spam_files = glob.glob(spam_path)\n",
      "ham_files = glob.glob(ham_path)\n",
      "\n",
      "print \"Total spam files =>\", len(spam_files)\n",
      "print \"Total ham files =>\", len(ham_files)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Total spam files => 1396\n",
        "Total ham files => 2501\n"
       ]
      }
     ],
     "prompt_number": 187
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_file_text(files):\n",
      "    \"\"\" Helper func to extract text from files \"\"\"\n",
      "    return [open(_file, 'r').read() for _file in files]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 188
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "spam_text = get_file_text(spam_files[:2])\n",
      "ham_text = get_file_text(ham_files[:2])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 189
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cv = CountVectorizer(decode_error=\"ignore\", stop_words=stop_words)\n",
      "\n",
      "train = cv.fit_transform(spam_text + ham_text).toarray()\n",
      "train_features = cv.get_feature_names()\n",
      "\n",
      "print \"Training matrix shape =>\", train.shape\n",
      "\n",
      "token_per_email = np.sum(train, axis=1)\n",
      "count_per_token = np.sum(train, axis=0)\n",
      "\n",
      "print \"Most frequent token =>\", train_features[np.argmax(count_per_token)]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Training matrix shape => (4, 810)\n",
        "Most frequent token => com\n"
       ]
      }
     ],
     "prompt_number": 190
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "train_labels = np.array([0] * len(spam_text) + [1] * len(ham_text))\n",
      "\n",
      "ham_tokens = train[train_labels==0]\n",
      "ham_token_count = np.sum(ham_tokens, axis=0) + 1\n",
      "\n",
      "ham_token_rate = ham_token_count.astype(float)/ham_tokens.shape[0]\n",
      "\n",
      "spam_tokens = train[train_labels==1]\n",
      "spam_token_count = np.sum(spam_tokens, axis=0) + 1\n",
      "\n",
      "spam_token_rate = spam_token_count.astype(float)/spam_tokens.shape[0]\n",
      "\n",
      "ham_to_spam_ratio = ham_token_rate/spam_token_rate\n",
      "\n",
      "print train_features[np.argmax(ham_to_spam_ratio)]\n",
      "\n",
      "spam_to_ham_ratio = spam_token_rate/ham_token_rate\n",
      "\n",
      "print train_features[np.argmax(spam_to_ham_ratio)]\n",
      "\n",
      "\n",
      "#Test data\n",
      "X_train, X_test, y_train, y_test = train_test_split(train, train_labels,\n",
      "                                                    test_size=0.4,\n",
      "                                                    random_state=0)\n",
      "\n",
      "\n",
      "# Setup model\n",
      "model = MultinomialNB().fit(X_train, y_train)\n",
      "preds = model.predict(X_test)\n",
      "\n",
      "test = cv.transform([\"fork my GitHub repo\", \"buy a car\"])\n",
      "\n",
      "model = MultinomialNB().fit(train, train_labels)\n",
      "\n",
      "print model.predict(test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "95\n",
        "aug\n",
        "[0 1]\n"
       ]
      }
     ],
     "prompt_number": 202
    }
   ],
   "metadata": {}
  }
 ]
}